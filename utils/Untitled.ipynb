{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, img_size=416):\n",
    "        with open(path, 'r') as f:\n",
    "            self.images = f.read().splitlines()\n",
    "            self.images = list(filter(lambda x: len(x) > 0, self.images))\n",
    "        assert len(self.images) > 0, 'No images found in {}'.format(path)\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.labels = [x.replace('images', 'labels').replace('.bmp','.txt').replace('.jpg','.txt').replace('.png','txt') for x in self.images]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_pth = self.images[idx]\n",
    "        label_pth = self.labels[idx]\n",
    "        img = cv2.imread(img_pth) # BGR\n",
    "        assert img is not None, 'File Not Found: {}'.format(img_pth)\n",
    "        \n",
    "        h, w, _ = img.shape\n",
    "        img, ratio, padw, padh = letterbox(img, height=self.img_size)\n",
    "        \n",
    "        # load label\n",
    "        labels = []\n",
    "        with open(label_pth, 'r') as f:\n",
    "            lines = f.read().splitlines()\n",
    "        assert lines is not None, 'No annotations in: {}'.format(label_pth)\n",
    "        \n",
    "        x = np.array([x.split() for x in lines], dtype=np.float32)\n",
    "        if x.size > 0:\n",
    "            # shit xywh to pixel xyxy of padded.\n",
    "            labels = x.copy()\n",
    "            labels[:, 1] = ratio * w * (x[:, 1] - x[:, 3] / 2) + padw\n",
    "            labels[:, 2] = ratio * h * (x[:, 2] - x[:, 4] / 2) + padh\n",
    "            labels[:, 3] = ratio * w * (x[:, 1] + x[:, 3] / 2) + padw\n",
    "            labels[:, 4] = ratio * h * (x[:, 2] + x[:, 4] / 2) + padh\n",
    "            \n",
    "        nL = len(labels) # num of labels\n",
    "        \n",
    "        # convert xyxy to xywh\n",
    "        labels[:, 1:5] = xyxy2xywh(labels[:, 1:5]) / self.img_size\n",
    "            \n",
    "        labels_out = torch.zeros((nL, 6))\n",
    "        labels_out[:, 1:] = torch.from_numpy(labels)\n",
    "        \n",
    "        # Normalize\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "        img = np.ascontiguousarray(img, dtype=np.float32)  # uint8 to float32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "\n",
    "        return torch.from_numpy(img), labels_out, img_path, (h, w)\n",
    "    \n",
    "def letterbox(img, height=416, color=(127.5, 127.5, 127.5)):\n",
    "    # Resize a rectangular image to a padded square\n",
    "    shape = img.shape[:2]  # shape = [height, width]\n",
    "    ratio = float(height) / max(shape)  # ratio  = old / new\n",
    "    new_shape = (round(shape[1] * ratio), round(shape[0] * ratio))\n",
    "    dw = (height - new_shape[0]) / 2  # width padding\n",
    "    dh = (height - new_shape[1]) / 2  # height padding\n",
    "    top, bottom = round(dh - 0.1), round(dh + 0.1)\n",
    "    left, right = round(dw - 0.1), round(dw + 0.1)\n",
    "    img = cv2.resize(img, new_shape, interpolation=cv2.INTER_AREA)  # resized, no border\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # padded square\n",
    "    return img, ratio, dw, dh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 3 4 5', '2 3 5 4 6', '3 6 5 8 9']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    with open('a.txt','r') as f:\n",
    "        d = f.read().splitlines()\n",
    "except:\n",
    "    print('no such files')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([x.split() for x in d], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4., 5.],\n",
       "       [2., 3., 5., 4., 6.],\n",
       "       [3., 6., 5., 8., 9.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
