{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils.datasets import LoadDataset\n",
    "from utils import torch_utils\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from models import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# specify visible GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = torch_utils.select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 416\n",
    "EPOCHES = 270\n",
    "BATCH_SIZE = 16\n",
    "CFG = 'cfg/yolov3.cfg'\n",
    "DATA_CFG = 'cfg/coco.data'\n",
    "NUM_WORKERS = 1\n",
    "FROM_SCRATCH = True\n",
    "\n",
    "weights = 'weights/'\n",
    "latest = os.path.join(weights, 'latest.pt')\n",
    "best = os.path.join(weights, 'best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = parse_data_cfg(DATA_CFG)['train'];train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = LoadDataset(train_file_pth, img_size=IMG_SIZE);dataset[122][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = Darknet(CFG, IMG_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False, pin_memory=True, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Dataloader\n",
    "for i, (imgs, targets, _, _) in enumerate(dataloader):\n",
    "    #print(targets.shape)\n",
    "    plot_images(imgs=imgs, targets=targets, fname='train_batch0.jpg')\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = -1  # backbone reaches to cutoff layer\n",
    "START_EPOCH = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "if not FROM_SCRATCH:\n",
    "    if '-tiny.cfg' in CFG:\n",
    "        cutoff = load_darknet_weights(model, weights + 'yolov3-tiny.conv.15')\n",
    "    else:\n",
    "        cutoff = load_darknet_weights(model, weights + 'darknet53.conv.74')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "lr0 = 0.001  # initial learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr0, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Scheduler (reduce lr at epochs 218, 245, i.e. batches 400k, 450k)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[218, 245], gamma=0.1,\n",
    "                                                 last_epoch=start_epoch - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "t = time.time()\n",
    "nB = len(dataloader) # num of batches\n",
    "n_burnin = min(round(nB / 5 + 1), 1000)\n",
    "accumulate = 1\n",
    "multi_scale = False\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHES):\n",
    "    model.train()\n",
    "    print(('\\n%8s%12s' + '%10s' * 7) % ('Epoch', 'Batch', 'xy', 'wh', 'conf', 'cls', 'total', 'nTargets', 'time'))\n",
    "\n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Freeze backbone at epoch 0, unfreeze at epoch 1\n",
    "    if freeze_backbone and epoch < 2:\n",
    "        for name, p in model.named_parameters():\n",
    "            if int(name.split('.')[1]) < cutoff:  # if layer < 75\n",
    "                p.requires_grad = False if epoch == 0 else True\n",
    "\n",
    "    mloss = torch.zeros(5).to(device) # mean losses\n",
    "    for i, (imgs, targets, _, _) in enumerate(dataloader):\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        nt = len(targets)\n",
    "\n",
    "        # SGD burn-in\n",
    "        if epoch == 0 and i <= n_burnin:\n",
    "            lr = lr0 * (i / n_burnin) ** 4\n",
    "            for x in optimizer.param_groups:\n",
    "                x['lr'] = lr\n",
    "\n",
    "        # Run model\n",
    "        pred = model(imgs)\n",
    "\n",
    "        # Build targets\n",
    "        target_list = build_targets(model, targets)\n",
    "\n",
    "        # Compute loss\n",
    "        loss, loss_items = compute_loss(pred, target_list)\n",
    "\n",
    "        # Compute gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Accumulate gradient for x batches before optimizing\n",
    "        if (i + 1) % accumulate == 0 or (i + 1) == nB:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Update running mean of tracked metrics\n",
    "        mloss = (mloss * i + loss_items) / (i + 1)\n",
    "\n",
    "        # Print batch results\n",
    "        s = ('%8s%12s' + '%10.3g' * 7) % (\n",
    "            '%g/%g' % (epoch, epochs - 1),\n",
    "            '%g/%g' % (i, nB - 1), *mloss, nt, time.time() - t)\n",
    "        t = time.time()\n",
    "        print(s)\n",
    "\n",
    "        # Multi-Scale training (320 - 608 pixels) every 10 batches\n",
    "        if multi_scale and (i + 1) % 10 == 0:\n",
    "            dataset.img_size = random.choice(range(10, 20)) * 32\n",
    "            print('multi_scale img_size = %g' % dataset.img_size)\n",
    "\n",
    "    # Calculate mAP\n",
    "    with torch.no_grad():\n",
    "        results = test.test(CFG, DATA_CFG, batch_size=BATCH_SIZE, img_size=IMG_SIZE, model=model, conf_thres=0.1)\n",
    "\n",
    "    # Write epoch results\n",
    "    with open('results.txt', 'a') as file:\n",
    "        file.write(s + '%11.3g' * 5 % results + '\\n')  # P, R, mAP, F1, test_loss\n",
    "\n",
    "    # Update best loss\n",
    "    test_loss = results[4]\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "\n",
    "    # Save training results\n",
    "    save = True and not opt.nosave\n",
    "    if save:\n",
    "        # Create checkpoint\n",
    "        chkpt = {'epoch': epoch,\n",
    "                 'best_loss': best_loss,\n",
    "                 'model': model.module.state_dict() if type(\n",
    "                     model) is nn.parallel.DistributedDataParallel else model.state_dict(),\n",
    "                 'optimizer': optimizer.state_dict()}\n",
    "\n",
    "        # Save latest checkpoint\n",
    "        torch.save(chkpt, latest)\n",
    "\n",
    "        # Save best checkpoint\n",
    "        if best_loss == test_loss:\n",
    "            torch.save(chkpt, best)\n",
    "\n",
    "        # Save backup every 10 epochs (optional)\n",
    "        if epoch > 0 and epoch % 10 == 0:\n",
    "            torch.save(chkpt, weights + 'backup%g.pt' % epoch)\n",
    "\n",
    "        # Delete checkpoint\n",
    "        del chkpt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
