{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network.....\n",
      "Network successfully loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\Anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\dog.jpg predicted in  1.443 seconds\n",
      "Objects Detected:    bicycle truck dog\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\eagle.jpg predicted in  1.469 seconds\n",
      "Objects Detected:    bird\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\giraffe.jpg predicted in  1.454 seconds\n",
      "Objects Detected:    zebra giraffe giraffe\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\herd_of_horses.jpg predicted in  1.409 seconds\n",
      "Objects Detected:    horse horse horse horse\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\img1.jpg predicted in  1.418 seconds\n",
      "Objects Detected:    person dog\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\img2.jpg predicted in  1.420 seconds\n",
      "Objects Detected:    train\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\img3.jpg predicted in  1.434 seconds\n",
      "Objects Detected:    car car car car car car car truck traffic light\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\img4.jpg predicted in  1.410 seconds\n",
      "Objects Detected:    chair chair chair clock\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\messi.jpg predicted in  1.411 seconds\n",
      "Objects Detected:    person person person sports ball\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\person.jpg predicted in  1.396 seconds\n",
      "Objects Detected:    person dog horse\n",
      "----------------------------------------------------------\n",
      "E:\\condaDev\\YOLO_v3_tutorial_from_scratch-master\\imgs\\scream.jpg predicted in  1.423 seconds\n",
      "Objects Detected:    \n",
      "----------------------------------------------------------\n",
      "SUMMARY\n",
      "----------------------------------------------------------\n",
      "Task                     : Time Taken (in seconds)\n",
      "\n",
      "Reading addresses        : 0.001\n",
      "Loading batch            : 0.135\n",
      "Detection (11 images)    : 15.697\n",
      "Output Processing        : 0.000\n",
      "Drawing Boxes            : 0.167\n",
      "Average time_per_img     : 1.454\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run detect.py --images imgs --det det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](yolo3jiagou.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 507, 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 507, 85])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(1, 255, 13, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 255, 13, 13])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13, 255, 13])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c.view(1,13*13*3,85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 507, 85])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [(116, 90), (156, 198), (373, 326)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [(a[0]/32, a[1]/32) for a in anchors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.625, 2.8125), (4.875, 6.1875), (11.65625, 10.1875)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.arange(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = np.meshgrid(grid, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
       "       [ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3],\n",
       "       [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n",
       "       [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
       "       [ 6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6],\n",
       "       [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
       "       [ 8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8],\n",
       "       [ 9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9],\n",
       "       [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "       [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
       "       [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset = torch.FloatTensor(a).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_offset = torch.FloatTensor(b).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1,3).view(-1,2).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 507, 2])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_y_offset.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        [ 0.,  0.],\n",
       "        ...,\n",
       "        [12., 12.],\n",
       "        [12., 12.],\n",
       "        [12., 12.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x_offset, y_offset), 1).repeat(1,3).view(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=torch.cat((x_offset, y_offset), 1).repeat(1,3).view(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([507, 2])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1014"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "169*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  ..., 25., 25., 25.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_y_offset[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10647"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "507+2028+8112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "a = time.time()\n",
    "b = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[416, 416, 416, 416, 416, 416, 416, 416, 416, 416, 416]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[416 for x in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def letterbox_image(img, inp_dim):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    img_w, img_h = img.shape[1], img.shape[0]\n",
    "    w, h = inp_dim\n",
    "    new_w = int(img_w * min(w/img_w, h/img_h))\n",
    "    new_h = int(img_h * min(w/img_w, h/img_h))\n",
    "    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n",
    "\n",
    "    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n",
    "    \n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dog-cycle-car.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 602, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = letterbox_image(img,416)\n",
    "canvas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "images = 'imgs'\n",
    "imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\dog.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\eagle.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\giraffe.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\herd_of_horses.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\img1.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\img2.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\img3.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\img4.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\messi.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\person.jpg',\n",
       " 'E:\\\\condaDev\\\\YOLO_v3_tutorial_from_scratch-master\\\\imgs\\\\scream.jpg']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_ims = [cv2.imread(x) for x in imlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        ...,\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128]],\n",
       "\n",
       "       [[128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        ...,\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128]],\n",
       "\n",
       "       [[128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        ...,\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        ...,\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128]],\n",
       "\n",
       "       [[128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        ...,\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128]],\n",
       "\n",
       "       [[128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        ...,\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128],\n",
       "        [128, 128, 128]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "inp_dim = 416\n",
    "canvas = letterbox_image(img, (inp_dim, inp_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
