{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from models import *\n",
    "from utils.datasets import *\n",
    "from utils.utils import *\n",
    "from utils import torch_utils\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = 'cfg/yolov3-spp.cfg'\n",
    "data_cfg = 'data/coco.data'\n",
    "weights = 'weights/yolov3-spp.weights'\n",
    "images = 'samples/'\n",
    "output = 'output'\n",
    "save_images=True\n",
    "img_size = 416\n",
    "conf_thres = 0.5\n",
    "nms_thres = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ultralytics/yolov3/blob/master/detect.py\n",
    "def detect(\n",
    "        cfg=cfg,\n",
    "        data_cfg=data_cfg,\n",
    "        weights=weights,\n",
    "        images=images,\n",
    "        output=output,\n",
    "        img_size=img_size,\n",
    "        conf_thres=conf_thres,\n",
    "        nms_thres=nms_thres,\n",
    "        save_images=True\n",
    "        ):\n",
    "    \n",
    "    device = torch_utils.select_device()\n",
    "    \n",
    "    if os.path.exists(output):\n",
    "        shutil.rmtree(output)  # delete output folder\n",
    "    os.makedirs(output)  # make new output folder\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Darknet(cfg, img_size)\n",
    "    \n",
    "    # Load weights\n",
    "    if weights.endswith('.pt'):  # pytorch format\n",
    "        model.load_state_dict(torch.load(weights, map_location=device)['model'])\n",
    "    else:  # darknet format\n",
    "        _ = load_darknet_weights(model, weights)\n",
    "        \n",
    "    model.to(device).eval()\n",
    "    \n",
    "    # Set Dataloader\n",
    "    vid_path, vid_writer = None, None\n",
    "    \n",
    "    dataloader = LoadImages(images, img_size=img_size)\n",
    "    \n",
    "    # Get classes and colors\n",
    "    classes = load_classes(parse_data_cfg(data_cfg)['names'])\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(classes))]\n",
    "    \n",
    "    for i, (path, img, im0, vid_cap) in enumerate(dataloader):\n",
    "        t = time.time()\n",
    "        #print(path)\n",
    "        save_path = str(Path(output) / Path(path).name)\n",
    "\n",
    "        # Get detections\n",
    "        img = torch.from_numpy(img).unsqueeze(0).to(device) # convert it to tensor and add 0 dim(batch)\n",
    "        #print(img.shape)\n",
    "\n",
    "        pred, _ = model(img)\n",
    "        detections = non_max_suppression(pred, conf_thres, nms_thres)[0]\n",
    "\n",
    "        if detections is not None and len(detections) > 0:\n",
    "            # Rescale boxes from 416 to true image size\n",
    "            scale_coords(img_size, detections[:, :4], im0.shape).round()\n",
    "\n",
    "            # Print results to screen\n",
    "            for c in detections[:, -1].unique():\n",
    "                n = (detections[:, -1] == c).sum()\n",
    "                print('%g %ss' % (n, classes[int(c)]), end=', ')\n",
    "\n",
    "            # Draw bounding boxes and labels of detections\n",
    "            for *xyxy, conf, cls_conf, cls in detections:\n",
    "                # Add bbox to the image\n",
    "                label = '%s %.2f' % (classes[int(cls)], conf)\n",
    "                plot_one_box(xyxy, im0, label=label, color=colors[int(cls)])\n",
    "\n",
    "        print('Done. (%.3fs)' % (time.time() - t))\n",
    "\n",
    "        if save_images:\n",
    "            cv2.imwrite(save_path, im0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU.\n",
      "image 1/15 samples\\Adrian.jpg: 2 persons, 8 cars, 3 potted plants, 1 traffic lights, Done. (1.083s)\n",
      "image 2/15 samples\\India.jpg: 8 persons, 1 cell phones, Done. (1.218s)\n",
      "image 3/15 samples\\Starks.jpg: 3 persons, Done. (1.217s)\n",
      "image 4/15 samples\\Trump.jpg: 2 persons, 1 ties, Done. (1.190s)\n",
      "image 5/15 samples\\Vector.jpg: 12 persons, Done. (1.500s)\n",
      "image 6/15 samples\\die-welle.jpg: 10 persons, Done. (1.226s)\n",
      "image 7/15 samples\\dog.jpg: 1 dogs, 1 bicycles, 1 trucks, Done. (1.286s)\n",
      "image 8/15 samples\\got-s8.jpg: 13 persons, Done. (1.338s)\n",
      "image 9/15 samples\\lifelines.jpg: 2 persons, 1 ties, Done. (1.251s)\n",
      "image 10/15 samples\\merlin.jpg: 1 trucks, 1 cars, 9 persons, 1 fire hydrants, 2 handbags, 1 dogs, Done. (1.269s)\n",
      "image 11/15 samples\\pornstar.jpg: 1 persons, Done. (1.208s)\n",
      "image 12/15 samples\\timg.jpg: 2 persons, Done. (1.315s)\n",
      "image 13/15 samples\\timg3.jpg: 4 persons, Done. (1.239s)\n",
      "image 14/15 samples\\walkers.jpg: 2 persons, Done. (1.170s)\n",
      "image 15/15 samples\\zidane.jpg: 2 persons, 1 ties, Done. (1.232s)\n"
     ]
    }
   ],
   "source": [
    "detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_detect(\n",
    "        cfg=cfg,\n",
    "        data_cfg=data_cfg,\n",
    "        weights=weights,\n",
    "        images=images,\n",
    "        output=output,\n",
    "        img_size=img_size,\n",
    "        conf_thres=conf_thres,\n",
    "        nms_thres=nms_thres,\n",
    "        save_images=True\n",
    "        ):\n",
    "    \n",
    "    device = torch_utils.select_device()\n",
    "    \n",
    "    if os.path.exists(output):\n",
    "        shutil.rmtree(output)  # delete output folder\n",
    "    os.makedirs(output)  # make new output folder\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Darknet(cfg, img_size)\n",
    "    \n",
    "    # Load weights\n",
    "    if weights.endswith('.pt'):  # pytorch format\n",
    "        model.load_state_dict(torch.load(weights, map_location=device)['model'])\n",
    "    else:  # darknet format\n",
    "        _ = load_darknet_weights(model, weights)\n",
    "        \n",
    "    model.to(device).eval()\n",
    "    \n",
    "    # Set Dataloader\n",
    "    vid_path, vid_writer = None, None\n",
    "    \n",
    "    #dataloader = LoadImages(images, img_size=img_size)\n",
    "    dataset = MyLoadImages(images, img_size=img_size) # Pytorch dataset\n",
    "    dataloader = DataLoader(dataset, batch_size=1, num_workers=1, shuffle=False) # Pytorch dataloader\n",
    "    \n",
    "    # Get classes and colors\n",
    "    classes = load_classes(parse_data_cfg(data_cfg)['names'])\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(classes))]\n",
    "    \n",
    "    for i, (path, img, im0) in enumerate(dataloader):\n",
    "        t = time.time()\n",
    "        path = ''.join(path)\n",
    "        save_path = str(Path(output) / Path(path).name)\n",
    "\n",
    "        # Get detections\n",
    "        #img = torch.from_numpy(img).unsqueeze(0).to(device)\n",
    "        img = img.to(device) # already tensor, shift to device\n",
    "        #print(img.shape)\n",
    "        im0 = im0.squeeze(0).numpy() # convert it to numpy and remove batch dim\n",
    "\n",
    "        pred, _ = model(img)\n",
    "        detections = non_max_suppression(pred, conf_thres, nms_thres)[0]\n",
    "\n",
    "        if detections is not None and len(detections) > 0:\n",
    "            # Rescale boxes from 416 to true image size\n",
    "            scale_coords(img_size, detections[:, :4], im0.shape).round()\n",
    "\n",
    "            # Print results to screen\n",
    "            print('{}/{} image: {} '.format(i, len(dataset), path), end='')\n",
    "            for c in detections[:, -1].unique():\n",
    "                n = (detections[:, -1] == c).sum()\n",
    "                print('%g %ss' % (n, classes[int(c)]), end=', ')\n",
    "\n",
    "            # Draw bounding boxes and labels of detections\n",
    "            for *xyxy, conf, cls_conf, cls in detections:\n",
    "                # Add bbox to the image\n",
    "                label = '%s %.2f' % (classes[int(cls)], conf)\n",
    "                plot_one_box(xyxy, im0, label=label, color=colors[int(cls)])\n",
    "\n",
    "        print('Done. (%.3fs)' % (time.time() - t))\n",
    "\n",
    "        if save_images:\n",
    "            cv2.imwrite(save_path, im0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU.\n",
      "0/15 image: samples/Adrian.jpg 2 persons, 8 cars, 3 potted plants, 1 traffic lights, Done. (1.092s)\n",
      "1/15 image: samples/die-welle.jpg 10 persons, Done. (1.178s)\n",
      "2/15 image: samples/dog.jpg 1 dogs, 1 bicycles, 1 trucks, Done. (1.568s)\n",
      "3/15 image: samples/got-s8.jpg 13 persons, Done. (1.175s)\n",
      "4/15 image: samples/India.jpg 8 persons, 1 cell phones, Done. (1.148s)\n",
      "5/15 image: samples/lifelines.jpg 2 persons, 1 ties, Done. (1.245s)\n",
      "6/15 image: samples/merlin.jpg 1 trucks, 1 cars, 9 persons, 1 fire hydrants, 2 handbags, 1 dogs, Done. (1.365s)\n",
      "7/15 image: samples/pornstar.jpg 1 persons, Done. (1.304s)\n",
      "8/15 image: samples/Starks.jpg 3 persons, Done. (1.259s)\n",
      "9/15 image: samples/timg.jpg 2 persons, Done. (1.240s)\n",
      "10/15 image: samples/timg3.jpg 4 persons, Done. (1.156s)\n",
      "11/15 image: samples/Trump.jpg 2 persons, 1 ties, Done. (1.194s)\n",
      "12/15 image: samples/Vector.jpg 12 persons, Done. (1.291s)\n",
      "13/15 image: samples/walkers.jpg 2 persons, Done. (1.259s)\n",
      "14/15 image: samples/zidane.jpg 2 persons, 1 ties, Done. (1.755s)\n"
     ]
    }
   ],
   "source": [
    "My_detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
