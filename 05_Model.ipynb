{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### codes reference https://github.com/ydixon/yolo_v3/blob/master/yolo_detect.ipynb\n",
    "### a nice bolg for understanding. https://blog.csdn.net/leviopku/article/details/82660381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic network building blocks - conv_bn_relu, res_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://blog.csdn.net/leviopku/article/details/82660381, resn\n",
    "class conv_bn_relu(nn.Module):\n",
    "    def __init__(self, nin, nout, kernel, stride=1, pad=\"SAME\", padding=0, bn=True, activation=\"leakyRelu\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn = bn\n",
    "        self.activation = activation\n",
    "        \n",
    "        if pad == 'SAME':\n",
    "            padding = (kernel-1)//2\n",
    "            \n",
    "        self.conv = nn.Conv2d(nin, nout, kernel, stride, padding, bias=not bn)\n",
    "        if bn == True:\n",
    "            self.bn = nn.BatchNorm2d(nout)\n",
    "        if activation == \"leakyRelu\":\n",
    "            self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "    \n",
    "class res_layer(nn.Module):\n",
    "    def __init__(self, nin):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_bn_relu(nin, nin//2, kernel=1)  #64->32, 1\n",
    "        self.conv2 = conv_bn_relu(nin//2, nin, kernel=3)  #32->64, 3 see figure of darknet\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.conv2(self.conv1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map2cfgDict - used to creating mapping that follows the cfg file from prjreddit's repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map2cfgDict(mlist):\n",
    "    idx = 0 \n",
    "    mdict = OrderedDict()\n",
    "    for i,m in enumerate(mlist):\n",
    "        if isinstance(m, res_layer):\n",
    "            mdict[idx] = None\n",
    "            mdict[idx+1] = None\n",
    "            idx += 2\n",
    "        mdict[idx] = i\n",
    "        idx += 1\n",
    "    \n",
    "    return mdict        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UpsampleGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://blog.csdn.net/leviopku/article/details/82660381, DBL + 上采样\n",
    "class UpsampleGroup(nn.Module):\n",
    "    def __init__(self, nin):\n",
    "        super().__init__()\n",
    "        self.conv = conv_bn_relu(nin, nin//2, kernel=1)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        \n",
    "    def forward(self, route_head, route_tail):\n",
    "        out = self.up(self.conv(route_head))\n",
    "        return torch.cat((out, route_tail), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PreDetectionConvGroup - conv layers before the yolo detection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreDetectionConvGroup(nn.Module):\n",
    "    def __init__(self, nin, nout, num_conv=3, numClass=80):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlist = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_conv):\n",
    "            self.mlist += [conv_bn_relu(nin, nout, kernel=1)]\n",
    "            self.mlist += [conv_bn_relu(nout, nout*2, kernel=3)]\n",
    "            if i == 0:\n",
    "                nin = nout*2\n",
    "                \n",
    "        self.mlist += [nn.Conv2d(nin, (numClass+5)*3, 1)]\n",
    "        self.map2yolocfg = map2cfgDict(self.mlist)\n",
    "        self.cachedOutDict = dict()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i,m in enumerate(self.mlist):\n",
    "            x = m(x)\n",
    "            if i in self.cachedOutDict:\n",
    "                self.cachedOutDict[i] = x\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    #mode - normal  -- direct index to mlist \n",
    "    #     - yolocfg -- index follow the sequences of the cfg file from https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg\n",
    "    def addCachedOut(self, idx, mode=\"yolocfg\"):\n",
    "        if mode == \"yolocfg\":\n",
    "            idx = self.getIdxFromYoloIdx(idx)\n",
    "        elif idx < 0:\n",
    "            idx = len(self.mlist) - idx\n",
    "        \n",
    "        self.cachedOutDict[idx] = None\n",
    "        \n",
    "    def getCachedOut(self, idx, mode=\"yolocfg\"):\n",
    "        if mode == \"yolocfg\":\n",
    "            idx = self.getIdxFromYoloIdx(idx)\n",
    "        elif idx < 0:\n",
    "            idx = len(self.mlist) - idx\n",
    "        return self.cachedOutDict[idx]\n",
    "    \n",
    "    def getIdxFromYoloIdx(self,idx):\n",
    "        if idx < 0:\n",
    "            return len(self.map2yolocfg) + idx\n",
    "        else:\n",
    "            return self.map2yolocfg[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Darknet53 - Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_res_stack(nin, num_block):\n",
    "    return nn.ModuleList([conv_bn_relu(nin, nin*2, 3, stride=2)] + [res_layer(nin*2) for n in range(num_block)])\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "    def __init__(self, blkList, nout=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlist = nn.ModuleList()\n",
    "        self.mlist += [conv_bn_relu(3, nout, 3)]\n",
    "        for i,nb in enumerate(blkList):\n",
    "            self.mlist += make_res_stack(nout*(2**i), nb)\n",
    "            \n",
    "        self.map2yolocfg = map2cfgDict(self.mlist)\n",
    "        self.cachedOutDict = dict()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i,m in enumerate(self.mlist):\n",
    "            x = m(x)\n",
    "            if i in self.cachedOutDict:\n",
    "                self.cachedOutDict[i] = x\n",
    "        return x\n",
    "    \n",
    "    def addCachedOut(self, idx, mode=\"yolocfg\"):\n",
    "        if mode == \"yolocfg\":\n",
    "            idxs = self.map2yolocfg[idx]\n",
    "        self.cachedOutDict[idxs] = None\n",
    "        \n",
    "    def getCachedOut(self, idx, mode=\"yolocfg\"):\n",
    "        if mode == \"yolocfg\":\n",
    "            idxs = self.map2yolocfg[idx]\n",
    "        return self.cachedOutDict[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Darknet([1,2,8,8,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.addCachedOut(61)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yolo Detection Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLayer(nn.Module):\n",
    "    def __init__(self, anchors, img_dim, nClass):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.anchors = anchors # [(116, 90), (156, 198), (373, 326)]\n",
    "        self.img_dim = img_dim\n",
    "        self.nClass = nClass\n",
    "        self.bbox_attrib = nClass + 5\n",
    "        \n",
    "    def forward(self, x, img_dim):\n",
    "        # x: bs * nA(5 + nClass) * h * w\n",
    "        nB = x.shape[0] # batch_size\n",
    "        nA = len(self.anchors) # 3\n",
    "        nH, nW = x.shape[2], x.shape[3]\n",
    "        stride = img_dim / nH # 416/13=32\n",
    "        anchors = torch.FloatTensor(self.anchors) / stride\n",
    "        \n",
    "        ##Reshape predictions from [B x [A * (5 + numClass)] x H x W] to [B x A x H x W x (5 + numClass)]\n",
    "        # like:[1, 3, 85, 416, 416]->[1, 3, 416, 416, 85], see https://www.zhihu.com/question/60321866 for details.\n",
    "        preds = x.view(nB, nA, self.bbox_attrib, nH, nW).permute(0, 1, 3, 4, 2).contiguous()\n",
    "        \n",
    "        # tx, ty, tw, wh\n",
    "        preds_xy = preds[..., :2]            # = [:,:,:,:,:2], shape:torch.Size([1, 3, 416, 416, 2])\n",
    "        preds_wh = preds[..., 2:4]           # [x, y, w, h, 3-84]\n",
    "        preds_conf = preds[..., 4].sigmoid() # [x, y, w, h, conf, 4-84]\n",
    "        preds_cls = preds[..., 5:].sigmoid() # [x, y, w, h, conf, cls(80)]\n",
    "        \n",
    "        # Calculate cx, cy, anchor mesh\n",
    "        mesh_x = torch.arange(nW).repeat(nH,1).unsqueeze(2)              # H * W * 1\n",
    "        mesh_y = torch.arange(nH).repeat(nW,1).t().unsqueeze(2)          # H * W * 1\n",
    "        mesh_xy = torch.cat((mesh_x,mesh_y), 2)                          # H * W * 2\n",
    "        mesh_anchors = anchors.view(1, nA, 1, 1, 2).repeat(1, 1, nH, nW, 1) # 1 * nA * 1 * 1 * 2 -> 1 * nA * H * W * 2\n",
    "        \n",
    "        # pred_boxes holds bx,by,bw,bh\n",
    "        pred_boxes = torch.FloatTensor(preds[..., :4].shape)  # [1, 3, 416, 416, 4]\n",
    "        pred_boxes[..., :2] = preds_xy.detach().cpu().sigmoid() + mesh_xy # sig(tx) + cx, detach(): http://www.bnikolic.co.uk/blog/pytorch-detach.html\n",
    "        pred_boxes[..., 2:4] = preds_wh.detach().cpu().exp() * mesh_anchors  # exp(tw) * anchor\n",
    "        \n",
    "        # Return predictions if not training # # [1, 3, 416, 416, 85]\n",
    "        out = torch.cat((pred_boxes.cuda() * stride, \n",
    "                         preds_conf.cuda().unsqueeze(4),\n",
    "                         preds_cls.cuda() ), 4)\n",
    "        \n",
    "        # Reshape predictions from [B x A x H x W x (5 + numClass)] to [B x [A x H x W] x (5 + numClass)]\n",
    "        # such that predictions at different strides could be concatenated on the same dimension\n",
    "        out = out.permute(0, 2, 3, 1, 4).contiguous().view(nB, nA*nH*nW, self.bbox_attrib)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entire network - putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloNet(nn.Module):\n",
    "    def __init__(self, img_dim=None, anchors=[10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326], numClass=80):\n",
    "        super().__init__()\n",
    "        \n",
    "        nin = 32\n",
    "        self.numClass = numClass\n",
    "        self.img_dim = img_dim\n",
    "        self.stat_keys = ['loss', 'loss_x', 'loss_y', 'loss_w', 'loss_h', 'loss_conf', 'loss_cls',\n",
    "                          'nCorrect', 'nGT', 'recall']\n",
    "        \n",
    "        anchors = [(anchors[i], anchors[i+1]) for i in range(0,len(anchors),2)]\n",
    "        anchors = [anchors[i:i+3] for i in range(0, len(anchors), 3)][::-1]\n",
    "        \"\"\"\n",
    "        [[(116, 90), (156, 198), (373, 326)],\n",
    "         [(30, 61), (62, 45), (59, 119)],\n",
    "         [(10, 13), (16, 30), (33, 23)]]\n",
    "        \"\"\"\n",
    "        self.feature = Darknet([1,2,8,8,4]) # darknet 53\n",
    "        self.feature.addCachedOut(61)\n",
    "        self.feature.addCachedOut(36)\n",
    "        \n",
    "        self.pre_det1 = PreDetectionConvGroup(1024, 512, numClass=self.numClass)\n",
    "        self.yolo1 = YoloLayer(anchors[0], img_dim, self.numClass) # [(116, 90), (156, 198), (373, 326)]\n",
    "        self.pre_det1.addCachedOut(-3) #Fetch output from 4th layer backward including yolo layer\n",
    "        \n",
    "        self.up1 = UpsampleGroup(512)\n",
    "        self.pre_det2 = PreDetectionConvGroup(768, 256, numClass=self.numClass)\n",
    "        self.yolo2 = YoloLayer(anchors[1], img_dim, self.numClass) # [(30, 61), (62, 45), (59, 119)]\n",
    "        self.pre_det2.addCachedOut(-3)\n",
    "        \n",
    "        self.up2 = UpsampleGroup(256)\n",
    "        self.pre_det3 = PreDetectionConvGroup(384, 128, numClass=self.numClass)\n",
    "        self.yolo3 = YoloLayer(anchors[2], img_dim, self.numClass) # [(10, 13), (16, 30), (33, 23)]\n",
    "        \n",
    "        def forward(self, x):\n",
    "            img_dim = (x.shape[3], x.shape[2]) # w, h\n",
    "            \n",
    "            # extract features\n",
    "            out = self.feature(x)\n",
    "            \n",
    "            # detection layer 1\n",
    "            out = self.pre_det1(out)\n",
    "            det1 = self.yolo1(out, img_dim)\n",
    "            \n",
    "            # upsample 1\n",
    "            r_head1 = self.pre_det1.getCachedOut(-3)\n",
    "            r_tail1 = self.feature.getCachedOut(61)\n",
    "            out = self.up1(r_head1, r_tail1)\n",
    "            \n",
    "            # detection layer 2\n",
    "            out = self.pre_det2(out)\n",
    "            det2 = self.yolo2(out, img_dim)\n",
    "            \n",
    "            # upsample 2\n",
    "            r_head2 = self.pre_det2.getCachedOut(-3)\n",
    "            r_tail2 = self.feature.getCachedOut(36)\n",
    "            out = self.up2(r_head2, r_tail2)\n",
    "            \n",
    "            # detection layer 3\n",
    "            out = self.pre_det3(out)\n",
    "            det3 = self.yolo3(out, img_dim)\n",
    "            \n",
    "            return det1, det2, det3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YoloNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoloNet(\n",
       "  (feature): Darknet(\n",
       "    (mlist): ModuleList(\n",
       "      (0): conv_bn_relu(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (1): conv_bn_relu(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (2): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (3): conv_bn_relu(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (4): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (5): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (6): conv_bn_relu(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (7): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (8): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (9): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (10): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (11): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (12): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (13): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (14): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (15): conv_bn_relu(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (16): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (17): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (18): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (19): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (20): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (21): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (22): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (23): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (24): conv_bn_relu(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (25): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (26): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (27): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "      (28): res_layer(\n",
       "        (conv1): conv_bn_relu(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "        (conv2): conv_bn_relu(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_det1): PreDetectionConvGroup(\n",
       "    (mlist): ModuleList(\n",
       "      (0): conv_bn_relu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (1): conv_bn_relu(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (2): conv_bn_relu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (3): conv_bn_relu(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (4): conv_bn_relu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (5): conv_bn_relu(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (6): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (yolo1): YoloLayer()\n",
       "  (up1): UpsampleGroup(\n",
       "    (conv): conv_bn_relu(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (up): Upsample(scale_factor=2, mode=nearest)\n",
       "  )\n",
       "  (pre_det2): PreDetectionConvGroup(\n",
       "    (mlist): ModuleList(\n",
       "      (0): conv_bn_relu(\n",
       "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (1): conv_bn_relu(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (2): conv_bn_relu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (3): conv_bn_relu(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (4): conv_bn_relu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (5): conv_bn_relu(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (6): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (yolo2): YoloLayer()\n",
       "  (up2): UpsampleGroup(\n",
       "    (conv): conv_bn_relu(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (up): Upsample(scale_factor=2, mode=nearest)\n",
       "  )\n",
       "  (pre_det3): PreDetectionConvGroup(\n",
       "    (mlist): ModuleList(\n",
       "      (0): conv_bn_relu(\n",
       "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (1): conv_bn_relu(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (2): conv_bn_relu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (3): conv_bn_relu(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (4): conv_bn_relu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (5): conv_bn_relu(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      )\n",
       "      (6): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (yolo3): YoloLayer()\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
